{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, LeaveOneOut, GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import scikitplot as skplt\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats.stats import pearsonr\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Data Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_Data_25Jan.csv\").drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 2:].values\n",
    "y = df.iloc[:, 1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
    "scalar = StandardScaler().fit(X_train)\n",
    "X_train = scalar.transform(X_train)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Define functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leave_one_out(Data, model, PrincipalComponent = False, LinearDiscriminant = False):\n",
    "    X = Data.iloc[:, 2:].values\n",
    "    #sel = VarianceThreshold()\n",
    "    #sel.fit_transform(X)\n",
    "    y = Data.iloc[:, 1].values\n",
    "    loo = LeaveOneOut()\n",
    "    #model = RandomForestClassifier()\n",
    "    scores = []\n",
    "    preds = []\n",
    "    actuals = []\n",
    "    pca = PCA(n_components=10)    \n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scalar = MinMaxScaler().fit(X_train)\n",
    "        X_train = scalar.transform(X_train)\n",
    "        X_test = scalar.transform(X_test)\n",
    "\n",
    "        if PrincipalComponent == True:\n",
    "            pca = pca.fit(X_train)\n",
    "            X_train = pca.transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "        if LinearDiscriminant == True:\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            lda.fit(X_train, y_train)\n",
    "            X_train = lda.transform(X_train)\n",
    "            X_test = lda.transform(X_test)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        preds.append(model.predict(X_test)[0])\n",
    "        actuals.append(y_test[0])\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    \n",
    "    return preds, actuals, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hyper_Tune(clf, param_grid):\n",
    "    gs = GridSearchCV(estimator=clf, param_grid = param_grid,\n",
    "                 cv = 3, scoring = 'accuracy', refit = True)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Leave One Out*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - LOO with K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN-LOO Accuracy:  0.6068376068376068 \n",
      "\n",
      "Confusion Matrix: \n",
      "[[47 24]\n",
      " [22 24]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        71\n",
      "           1       0.50      0.52      0.51        46\n",
      "\n",
      "    accuracy                           0.61       117\n",
      "   macro avg       0.59      0.59      0.59       117\n",
      "weighted avg       0.61      0.61      0.61       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "clf_KNN = Hyper_Tune(clf, param_grid)\n",
    "Preds, Actuals, Scores = Leave_one_out(df, clf_KNN, PrincipalComponent=False, LinearDiscriminant=True)\n",
    "print(\"KNN-LOO Accuracy: \", np.mean(Scores), \"\\n\")\n",
    "confusion = confusion_matrix(Actuals, Preds)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion, \"\\n\")\n",
    "print(classification_report(Actuals, Preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LOO with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM-LOO Accuracy:  0.5641025641025641 \n",
      "\n",
      "Confusion Matrix: \n",
      "[[46 25]\n",
      " [26 20]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64        71\n",
      "           1       0.44      0.43      0.44        46\n",
      "\n",
      "    accuracy                           0.56       117\n",
      "   macro avg       0.54      0.54      0.54       117\n",
      "weighted avg       0.56      0.56      0.56       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(random_state=1, probability=True)\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    "clf_SVC = Hyper_Tune(clf, param_grid)\n",
    "Preds, Actuals, Scores = Leave_one_out(df, clf_SVC, PrincipalComponent=False, LinearDiscriminant=True)\n",
    "print(\"SVM-LOO Accuracy: \", np.mean(Scores), \"\\n\")\n",
    "confusion = confusion_matrix(Actuals, Preds)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion, \"\\n\")\n",
    "print(classification_report(Actuals, Preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LOO with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 91)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_sample_split = [2, 5, 10]\n",
    "min_sample_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'max_features': max_features,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_split': min_sample_split,\n",
    "              'min_samples_leaf': min_sample_leaf,\n",
    "              'bootstrap': bootstrap}\n",
    "clf_RF = Hyper_Tune(clf, param_grid)\n",
    "Preds, Actuals, Scores = Leave_one_out(df, clf_RF, PrincipalComponent=False, LinearDiscriminant=True)\n",
    "print(\"RF-LOO Accuracy: \", np.mean(Scores), \"\\n\")\n",
    "confusion = confusion_matrix(Actuals, Preds)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion, \"\\n\")\n",
    "print(classification_report(Actuals, Preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LOO with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammad/DataScience/Python/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Accuracy:  0.5811965811965812 \n",
      "\n",
      "Confusion Matrix: \n",
      "[[45 26]\n",
      " [23 23]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65        71\n",
      "           1       0.47      0.50      0.48        46\n",
      "\n",
      "    accuracy                           0.58       117\n",
      "   macro avg       0.57      0.57      0.57       117\n",
      "weighted avg       0.59      0.58      0.58       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_MLP = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(12, 4), random_state=1)\n",
    "Preds, Actuals, Scores = Leave_one_out(df, clf_MLP, PrincipalComponent=False, LinearDiscriminant=True)\n",
    "print(\"MLP-LOO Accuracy: \", np.mean(Scores), \"\\n\")\n",
    "confusion = confusion_matrix(Actuals, Preds)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion, \"\\n\")\n",
    "print(classification_report(Actuals, Preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble Voting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO Accuracy:  0.6324786324786325 \n",
      "\n",
      "Confusion Matrix: \n",
      "[[65  6]\n",
      " [37  9]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.75        71\n",
      "           1       0.60      0.20      0.30        46\n",
      "\n",
      "    accuracy                           0.63       117\n",
      "   macro avg       0.62      0.56      0.52       117\n",
      "weighted avg       0.62      0.63      0.57       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_ensemble = VotingClassifier(\n",
    "    estimators=[('Random Forest', clf_RF), ('K-NN', clf_KNN), ('SVC', clf_SVC)],\n",
    "    voting='hard')\n",
    "Preds, Actuals, Scores = Leave_one_out(df, clf_ensemble, PrincipalComponent=False)\n",
    "print(\"LOO Accuracy: \", np.mean(Scores), \"\\n\")\n",
    "confusion = confusion_matrix(Actuals, Preds)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion, \"\\n\")\n",
    "print(classification_report(Actuals, Preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Neural Networks*\n",
    "- Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test:  0.875 \n",
      "\n",
      "Confusion Matrix: \n",
      "[[15  3]\n",
      " [ 0  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        18\n",
      "           1       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.88        24\n",
      "   macro avg       0.83      0.92      0.85        24\n",
      "weighted avg       0.92      0.88      0.88        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_MLP = MLPClassifier(solver='lbfgs', alpha=1e-4, hidden_layer_sizes=(12, 4), random_state=1)\n",
    "clf_MLP.fit(X_train, y_train)\n",
    "print(\"Score on test: \", clf_MLP.score(X_test, y_test), \"\\n\")\n",
    "confusion = confusion_matrix(y_test, clf_MLP.predict(X_test))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion)\n",
    "print(classification_report(y_test, clf_MLP.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
